{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lalit2244/FOOD-WASTE-MANAGEMENT-SYSTEM/blob/main/app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PROJECT TITLE: FOOD WASTE MANAGEMENT SYSTEM"
      ],
      "metadata": {
        "id": "DFilsWqDiinD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GofnS1w5kohm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# REQUIREMENTS:\n",
        "gradio\n",
        "pandas\n",
        "matplotlib\n",
        "seaborn\n",
        "scikit-learn\n",
        "sqlite3\n"
      ],
      "metadata": {
        "id": "LpSvz7drisHX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# APP LINK: https://7d252f32d4e5ea5eeb.gradio.live"
      ],
      "metadata": {
        "id": "HpRDiyEIkiwz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FULL GRADIO APP (DATA+SQL+KPIS+AI ML)"
      ],
      "metadata": {
        "id": "yI6B-wQiRjQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Install dependencies (Colab / Local)\n",
        "# =========================\n",
        "!pip install gradio pandas numpy matplotlib seaborn scikit-learn sqlalchemy --quiet\n",
        "\n",
        "# Optional but recommended for better models:\n",
        "# !pip install xgboost --quiet\n",
        "\n",
        "# =========================\n",
        "# Full Gradio App\n",
        "# =========================\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sqlite3\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error, r2_score\n",
        "import traceback\n",
        "import datetime\n",
        "\n",
        "sns.set_theme()\n",
        "\n",
        "# -------------------------\n",
        "# Global state\n",
        "# -------------------------\n",
        "db_conn = None  # sqlite3 connection\n",
        "dataframes = {}  # name -> pandas.DataFrame\n",
        "\n",
        "# -------------------------\n",
        "# Helpers\n",
        "# -------------------------\n",
        "def read_uploaded_file(file_obj):\n",
        "    \"\"\"Safely read a gradio file-like to a pandas DataFrame\"\"\"\n",
        "    if file_obj is None:\n",
        "        return None\n",
        "    try:\n",
        "        # Gradio returns an object with .name in many cases,\n",
        "        # but sometimes it's already a file-like or path.\n",
        "        if hasattr(file_obj, \"name\") and isinstance(file_obj.name, str):\n",
        "            # Try reading bytes\n",
        "            return pd.read_csv(file_obj.name)\n",
        "        else:\n",
        "            # file_obj likely has .read()\n",
        "            file_bytes = file_obj.read()\n",
        "            return pd.read_csv(io.BytesIO(file_bytes))\n",
        "    except Exception:\n",
        "        try:\n",
        "            # last resort: try casting to pandas directly\n",
        "            return pd.read_csv(file_obj)\n",
        "        except Exception:\n",
        "            raise\n",
        "\n",
        "def ensure_db():\n",
        "    global db_conn\n",
        "    if db_conn is None:\n",
        "        db_conn = sqlite3.connect(\":memory:\", check_same_thread=False)\n",
        "\n",
        "def save_table_to_db(name):\n",
        "    \"\"\"Save dataframe to SQLite under given name\"\"\"\n",
        "    ensure_db()\n",
        "    dataframes[name].to_sql(name, db_conn, index=False, if_exists=\"replace\")\n",
        "\n",
        "def safe_to_markdown(df, n=10):\n",
        "    if df is None or df.empty:\n",
        "        return \"No results.\"\n",
        "    return df.head(n).to_markdown()\n",
        "\n",
        "# -------------------------\n",
        "# Upload dataset(s)\n",
        "# -------------------------\n",
        "def upload_file(file, table_name):\n",
        "    try:\n",
        "        if file is None:\n",
        "            return \"❌ No file uploaded.\"\n",
        "        df = read_uploaded_file(file)\n",
        "        if df is None:\n",
        "            return \"❌ Could not read file.\"\n",
        "        # Basic normalization: strip column names\n",
        "        df.columns = [str(c).strip() for c in df.columns]\n",
        "        dataframes[table_name] = df\n",
        "        save_table_to_db(table_name)\n",
        "        return f\"✅ `{table_name}` uploaded: {len(df)} rows, {len(df.columns)} cols.\\n\\nPreview:\\n{safe_to_markdown(df,5)}\"\n",
        "    except Exception as e:\n",
        "        return f\"❌ Error uploading file: {e}\\n\\n{traceback.format_exc()}\"\n",
        "\n",
        "# -------------------------\n",
        "# KPI functions\n",
        "# -------------------------\n",
        "def general_kpis():\n",
        "    rows = []\n",
        "    for name, df in dataframes.items():\n",
        "        rows.append({\n",
        "            \"table\": name,\n",
        "            \"rows\": len(df),\n",
        "            \"cols\": len(df.columns),\n",
        "            \"missing_values\": int(df.isnull().sum().sum())\n",
        "        })\n",
        "    if not rows:\n",
        "        return \"No tables loaded.\"\n",
        "    return pd.DataFrame(rows).to_markdown(index=False)\n",
        "\n",
        "def food_waste_kpis():\n",
        "    # expects tables: providers, receivers, food_listings, claims (if present)\n",
        "    if 'food_listings' not in dataframes:\n",
        "        return \"Load a `food_listings` table (filename suggested: food_listings_data.csv) to see food-specific KPIs.\"\n",
        "    fl = dataframes['food_listings']\n",
        "    total_items = len(fl)\n",
        "    total_quantity = int(fl['Quantity'].sum()) if 'Quantity' in fl.columns else \"N/A\"\n",
        "    unique_cities = int(fl['Location'].nunique()) if 'Location' in fl.columns else \"N/A\"\n",
        "    unique_food_types = int(fl['Food_Type'].nunique()) if 'Food_Type' in fl.columns else \"N/A\"\n",
        "    claims_count = len(dataframes['claims']) if 'claims' in dataframes else 0\n",
        "    completed = 0\n",
        "    if 'claims' in dataframes and 'Status' in dataframes['claims'].columns:\n",
        "        completed = int((dataframes['claims']['Status'] == 'Completed').sum())\n",
        "        completion_rate = f\"{(completed/claims_count*100):.1f}%\" if claims_count>0 else \"N/A\"\n",
        "    else:\n",
        "        completion_rate = \"N/A\"\n",
        "    md = (\n",
        "        f\"- Total food listings: **{total_items}**\\n\"\n",
        "        f\"- Total quantity: **{total_quantity}**\\n\"\n",
        "        f\"- Cities covered: **{unique_cities}**\\n\"\n",
        "        f\"- Food types: **{unique_food_types}**\\n\"\n",
        "        f\"- Claims: **{claims_count}**, Completed: **{completed}**, Completion Rate: **{completion_rate}**\"\n",
        "    )\n",
        "    return md\n",
        "\n",
        "# -------------------------\n",
        "# SQL runner\n",
        "# -------------------------\n",
        "def run_sql(query_text):\n",
        "    try:\n",
        "        ensure_db()\n",
        "        if query_text.strip() == \"\":\n",
        "            return \"Enter a SQL query.\"\n",
        "        df = pd.read_sql_query(query_text, db_conn)\n",
        "        # also return shape and a small preview\n",
        "        return f\"Rows returned: {len(df)}\\n\\nPreview:\\n{safe_to_markdown(df,10)}\"\n",
        "    except Exception as e:\n",
        "        return f\"SQL Error: {e}\\n\\n{traceback.format_exc()}\"\n",
        "\n",
        "# Predefined SQL templates for convenience\n",
        "PREDEFINED_QUERIES = {\n",
        "    \"Show tables\": \"SELECT name FROM sqlite_master WHERE type='table';\",\n",
        "    \"Top 10 food listings by quantity\": \"SELECT * FROM food_listings ORDER BY Quantity DESC LIMIT 10;\",\n",
        "    \"Total quantity by Location\": \"SELECT Location, SUM(Quantity) as Total_Q FROM food_listings GROUP BY Location ORDER BY Total_Q DESC LIMIT 20;\",\n",
        "    \"Claims count by Status\": \"SELECT Status, COUNT(*) as cnt FROM claims GROUP BY Status;\",\n",
        "    \"Providers count by City\": \"SELECT City, COUNT(*) as Provider_Count FROM providers GROUP BY City ORDER BY Provider_Count DESC;\"\n",
        "}\n",
        "\n",
        "# -------------------------\n",
        "# Visualizations\n",
        "# -------------------------\n",
        "def plot_bar(table_name, col):\n",
        "    try:\n",
        "        if table_name not in dataframes:\n",
        "            return None\n",
        "        df = dataframes[table_name]\n",
        "        if col not in df.columns:\n",
        "            return None\n",
        "        vc = df[col].value_counts().iloc[:50]\n",
        "        fig, ax = plt.subplots(figsize=(8,4))\n",
        "        sns.barplot(x=vc.values, y=vc.index, ax=ax)\n",
        "        ax.set_title(f\"Top values of {col}\")\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def plot_pie(table_name, col):\n",
        "    try:\n",
        "        if table_name not in dataframes:\n",
        "            return None\n",
        "        df = dataframes[table_name]\n",
        "        if col not in df.columns:\n",
        "            return None\n",
        "        vc = df[col].value_counts().iloc[:10]\n",
        "        fig, ax = plt.subplots(figsize=(6,6))\n",
        "        ax.pie(vc.values, labels=vc.index, autopct=\"%1.1f%%\", startangle=140)\n",
        "        ax.set_title(f\"Distribution of {col}\")\n",
        "        return fig\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def plot_heatmap_foodavailability():\n",
        "    # heatmap of Location vs Food_Type sum(Quantity)\n",
        "    if 'food_listings' not in dataframes:\n",
        "        return None\n",
        "    fl = dataframes['food_listings']\n",
        "    if not set(['Location','Food_Type','Quantity']).issubset(fl.columns):\n",
        "        return None\n",
        "    pivot = fl.pivot_table(index='Location', columns='Food_Type', values='Quantity', aggfunc='sum', fill_value=0)\n",
        "    fig, ax = plt.subplots(figsize=(10,6))\n",
        "    sns.heatmap(np.log1p(pivot), cmap='viridis', ax=ax)  # log scale for better visualization\n",
        "    ax.set_title(\"Log(Quantity+1) Heatmap: Location vs Food_Type\")\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "def plot_claims_trend():\n",
        "    if 'claims' not in dataframes:\n",
        "        return None\n",
        "    c = dataframes['claims'].copy()\n",
        "    if 'Timestamp' not in c.columns:\n",
        "        return None\n",
        "    # try to parse Timestamp\n",
        "    try:\n",
        "        c['ts'] = pd.to_datetime(c['Timestamp'])\n",
        "    except:\n",
        "        # attempt common formats\n",
        "        c['ts'] = pd.to_datetime(c['Timestamp'], errors='coerce')\n",
        "    c = c.dropna(subset=['ts'])\n",
        "    daily = c.groupby(c['ts'].dt.date).size().reset_index(name='count').sort_values('ts')\n",
        "    fig, ax = plt.subplots(figsize=(8,3))\n",
        "    sns.lineplot(x='ts', y='count', data=daily, marker='o', ax=ax)\n",
        "    ax.set_title(\"Daily claims trend\")\n",
        "    ax.set_xlabel(\"Date\")\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "# -------------------------\n",
        "# Search & filter food listings (and claim action)\n",
        "# -------------------------\n",
        "def search_food(query_text=\"\", food_types=None, locations=None, meal_types=None, provider_types=None,\n",
        "                qmin=None, qmax=None, limit=50):\n",
        "    if 'food_listings' not in dataframes:\n",
        "        return \"Load `food_listings` table first.\"\n",
        "    fl = dataframes['food_listings'].copy()\n",
        "    # case-insensitive search in Food_Name\n",
        "    if query_text:\n",
        "        fl = fl[fl['Food_Name'].str.contains(query_text, case=False, na=False)]\n",
        "    if food_types:\n",
        "        fl = fl[fl['Food_Type'].isin(food_types)]\n",
        "    if locations:\n",
        "        fl = fl[fl['Location'].isin(locations)]\n",
        "    if meal_types:\n",
        "        fl = fl[fl['Meal_Type'].isin(meal_types)]\n",
        "    if provider_types:\n",
        "        fl = fl[fl['Provider_Type'].isin(provider_types)]\n",
        "    if qmin is not None:\n",
        "        fl = fl[fl['Quantity'] >= qmin]\n",
        "    if qmax is not None:\n",
        "        fl = fl[fl['Quantity'] <= qmax]\n",
        "    if fl.empty:\n",
        "        return \"No items found with these filters.\"\n",
        "    return fl.head(limit).to_markdown()\n",
        "\n",
        "def claim_food(food_id, receiver_id, receiver_name=\"\"):\n",
        "    \"\"\"\n",
        "    Simulate creating a claim for given Food_ID and Receiver_ID.\n",
        "    Inserts a row into 'claims' dataframe & SQLite db.\n",
        "    \"\"\"\n",
        "    if 'food_listings' not in dataframes:\n",
        "        return \"Load food_listings first.\"\n",
        "    fl = dataframes['food_listings']\n",
        "    if 'Food_ID' not in fl.columns:\n",
        "        return \"food_listings must have a `Food_ID` column.\"\n",
        "    if food_id not in fl['Food_ID'].values:\n",
        "        return f\"Food_ID {food_id} not found.\"\n",
        "    # create claims table if not present\n",
        "    ensure_db()\n",
        "    now = datetime.datetime.utcnow().isoformat()\n",
        "    new_row = {\n",
        "        \"Claim_ID\": int(np.random.randint(10**6, 10**7)),\n",
        "        \"Food_ID\": int(food_id),\n",
        "        \"Receiver_ID\": int(receiver_id) if receiver_id is not None else None,\n",
        "        \"Status\": \"Pending\",\n",
        "        \"Timestamp\": now\n",
        "    }\n",
        "    if 'claims' in dataframes:\n",
        "        claims_df = dataframes['claims']\n",
        "        claims_df = pd.concat([claims_df, pd.DataFrame([new_row])], ignore_index=True)\n",
        "    else:\n",
        "        claims_df = pd.DataFrame([new_row])\n",
        "    dataframes['claims'] = claims_df\n",
        "    # sync to DB\n",
        "    save_table_to_db('claims')\n",
        "    return f\"✅ Claim created: Claim_ID {new_row['Claim_ID']} (Status: Pending)\"\n",
        "\n",
        "# -------------------------\n",
        "# ML: Claim Success Prediction (classification)\n",
        "# -------------------------\n",
        "def train_claim_classifier(model_name=\"RandomForest\", test_size=0.2, random_state=42):\n",
        "    # Needs 'claims' and 'food_listings' tables\n",
        "    if not set(['claims','food_listings']).issubset(dataframes.keys()):\n",
        "        return \"Need both `claims` and `food_listings` tables to train claim classifier.\"\n",
        "    claims = dataframes['claims'].copy()\n",
        "    fl = dataframes['food_listings'].copy()\n",
        "    # Merge on Food_ID\n",
        "    if 'Food_ID' not in claims.columns or 'Food_ID' not in fl.columns:\n",
        "        return \"Ensure 'Food_ID' exists in both tables.\"\n",
        "    merged = claims.merge(fl, on='Food_ID', how='left')\n",
        "    # Need Status column\n",
        "    if 'Status' not in merged.columns:\n",
        "        return \"Claims table needs a 'Status' column.\"\n",
        "    # Only keep rows with Status known\n",
        "    merged = merged[merged['Status'].notna()].copy()\n",
        "    if len(merged) < 30:\n",
        "        return f\"Not enough data to train (need >=30 rows, have {len(merged)}).\"\n",
        "    # target: Completed vs not\n",
        "    merged['target'] = (merged['Status'] == 'Completed').astype(int)\n",
        "    # Build features: Quantity, encode Food_Type, Meal_Type, Location, Provider_Type\n",
        "    features = []\n",
        "    X = pd.DataFrame()\n",
        "    if 'Quantity' in merged.columns:\n",
        "        X['Quantity'] = merged['Quantity'].fillna(0).astype(float)\n",
        "        features.append('Quantity')\n",
        "    # categorical encode using LabelEncoder for each\n",
        "    for col in ['Food_Type','Meal_Type','Location','Provider_Type']:\n",
        "        if col in merged.columns:\n",
        "            le = LabelEncoder()\n",
        "            X[col] = le.fit_transform(merged[col].astype(str))\n",
        "            features.append(col)\n",
        "    y = merged['target']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=float(test_size), random_state=int(random_state))\n",
        "    # choose model\n",
        "    try:\n",
        "        if model_name == \"LogisticRegression\":\n",
        "            model = LogisticRegression(max_iter=1000)\n",
        "        elif model_name == \"RandomForest\":\n",
        "            model = RandomForestClassifier(n_estimators=200, random_state=int(random_state))\n",
        "        else:\n",
        "            # try XGBoost if name matches and installed\n",
        "            try:\n",
        "                from xgboost import XGBClassifier\n",
        "                model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=int(random_state))\n",
        "            except Exception as e:\n",
        "                return f\"Model {model_name} not available (XGBoost missing). Install xgboost or choose another model.\"\n",
        "        model.fit(X_train, y_train)\n",
        "        preds = model.predict(X_test)\n",
        "        acc = accuracy_score(y_test, preds)\n",
        "        report = classification_report(y_test, preds, zero_division=0)\n",
        "        # feature importance if available\n",
        "        fi_text = \"\"\n",
        "        if hasattr(model, \"feature_importances_\"):\n",
        "            fi = pd.DataFrame({\"feature\": X.columns, \"importance\": model.feature_importances_}).sort_values('importance', ascending=False)\n",
        "            fi_text = \"\\nFeature importances:\\n\" + fi.to_markdown(index=False)\n",
        "        return f\"✅ Trained {model_name} classifier. Accuracy: {acc:.3f}\\n\\nClassification report:\\n{report}\\n{fi_text}\"\n",
        "    except Exception as e:\n",
        "        return f\"Training error: {e}\\n\\n{traceback.format_exc()}\"\n",
        "\n",
        "# -------------------------\n",
        "# ML: Demand Forecasting (regression)\n",
        "# -------------------------\n",
        "def train_demand_model(model_name=\"RandomForest\", test_size=0.2, random_state=42):\n",
        "    if 'food_listings' not in dataframes:\n",
        "        return \"Load `food_listings` table.\"\n",
        "    fl = dataframes['food_listings'].copy()\n",
        "    # Aggregate by (Location, Food_Type) -> Quantity sum\n",
        "    if not set(['Location','Food_Type','Quantity']).issubset(fl.columns):\n",
        "        return \"food_listings must have columns: Location, Food_Type, Quantity\"\n",
        "    agg = fl.groupby(['Location','Food_Type'])['Quantity'].sum().reset_index()\n",
        "    # Encode Location & Food_Type\n",
        "    le_loc = LabelEncoder()\n",
        "    le_food = LabelEncoder()\n",
        "    X = pd.DataFrame({\n",
        "        'Location_enc': le_loc.fit_transform(agg['Location'].astype(str)),\n",
        "        'FoodType_enc': le_food.fit_transform(agg['Food_Type'].astype(str))\n",
        "    })\n",
        "    y = agg['Quantity'].astype(float)\n",
        "    if len(X) < 10:\n",
        "        return \"Not enough aggregated examples (need >=10) to train demand model.\"\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=float(test_size), random_state=int(random_state))\n",
        "    try:\n",
        "        if model_name == \"LinearRegression\":\n",
        "            model = LinearRegression()\n",
        "        else:\n",
        "            model = RandomForestRegressor(n_estimators=200, random_state=int(random_state))\n",
        "        model.fit(X_train, y_train)\n",
        "        preds = model.predict(X_test)\n",
        "        mse = mean_squared_error(y_test, preds)\n",
        "        r2 = r2_score(y_test, preds)\n",
        "        # keep encoders & model in global for prediction\n",
        "        global demand_model_state\n",
        "        demand_model_state = {\n",
        "            \"model\": model,\n",
        "            \"le_loc\": le_loc,\n",
        "            \"le_food\": le_food,\n",
        "            \"agg\": agg\n",
        "        }\n",
        "        return f\"✅ Trained {model_name} demand model.\\nMSE: {mse:.2f}, R²: {r2:.3f}\\nYou can now predict demand for Location & Food_Type.\"\n",
        "    except Exception as e:\n",
        "        return f\"Training error: {e}\\n\\n{traceback.format_exc()}\"\n",
        "\n",
        "def predict_demand(location, food_type):\n",
        "    if 'demand_model_state' not in globals():\n",
        "        return \"Train a demand model first.\"\n",
        "    state = demand_model_state\n",
        "    model = state['model']\n",
        "    le_loc = state['le_loc']\n",
        "    le_food = state['le_food']\n",
        "    try:\n",
        "        loc_enc = le_loc.transform([location])[0] if location in le_loc.classes_ else None\n",
        "        food_enc = le_food.transform([food_type])[0] if food_type in le_food.classes_ else None\n",
        "        # If new unseen, approximate by nearest or return message\n",
        "        if loc_enc is None or food_enc is None:\n",
        "            return \"Location or Food_Type unseen by model. Train with more data including this location/type.\"\n",
        "        Xp = np.array([[loc_enc, food_enc]])\n",
        "        pred = model.predict(Xp)[0]\n",
        "        return f\"📈 Predicted demand (units): {pred:.1f}\"\n",
        "    except Exception as e:\n",
        "        return f\"Prediction error: {e}\\n\\n{traceback.format_exc()}\"\n",
        "\n",
        "# -------------------------\n",
        "# Utility: download a table as CSV (return bytes)\n",
        "# -------------------------\n",
        "def download_table_csv(table_name):\n",
        "    if table_name not in dataframes:\n",
        "        return None\n",
        "    csv_bytes = dataframes[table_name].to_csv(index=False).encode()\n",
        "    return io.BytesIO(csv_bytes)\n",
        "\n",
        "# -------------------------\n",
        "# Build Gradio UI\n",
        "# -------------------------\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# 🍽️ Food Waste Management — Gradio All-in-One\")\n",
        "    gr.Markdown(\"Upload datasets, run SQL, visualize, search, claim and train ML models — all from this UI. Use the `share=True` link to get a public URL.\")\n",
        "\n",
        "    with gr.Tab(\"1️⃣ Upload Data\"):\n",
        "        gr.Markdown(\"Upload CSV files and give them table names (suggested names: providers, receivers, food_listings, claims).\")\n",
        "        with gr.Row():\n",
        "            file_input = gr.File(label=\"CSV file\")\n",
        "            name_input = gr.Textbox(label=\"Table name (e.g. food_listings)\", value=\"mytable\")\n",
        "            upload_btn = gr.Button(\"Upload to DB\")\n",
        "        upload_output = gr.Textbox(label=\"Upload status\")\n",
        "        download_name = gr.Textbox(label=\"Table name to download\", value=\"food_listings\")\n",
        "        download_btn = gr.Button(\"Download CSV\")\n",
        "        download_file = gr.File(label=\"Download CSV\")\n",
        "        upload_btn.click(upload_file, inputs=[file_input, name_input], outputs=[upload_output])\n",
        "        download_btn.click(download_table_csv, inputs=[download_name], outputs=[download_file])\n",
        "\n",
        "    with gr.Tab(\"2️⃣ KPIs\"):\n",
        "        gr.Markdown(\"General KPIs for all loaded tables and food-waste-specific KPIs.\")\n",
        "        kpi_gen_btn = gr.Button(\"Show General KPIs\")\n",
        "        kpi_gen_out = gr.Textbox()\n",
        "        kpi_fw_btn = gr.Button(\"Show Food Waste KPIs\")\n",
        "        kpi_fw_out = gr.Markdown()\n",
        "        kpi_gen_btn.click(lambda: general_kpis(), inputs=None, outputs=kpi_gen_out)\n",
        "        kpi_fw_btn.click(lambda: food_waste_kpis(), inputs=None, outputs=kpi_fw_out)\n",
        "\n",
        "    with gr.Tab(\"3️⃣ Visualizations\"):\n",
        "        gr.Markdown(\"Select table & column to plot. Also special heatmap & claims trend.\")\n",
        "        with gr.Row():\n",
        "            viz_table = gr.Textbox(label=\"Table name\", value=\"food_listings\")\n",
        "            viz_col = gr.Textbox(label=\"Column name (for bar/pie)\")\n",
        "        with gr.Row():\n",
        "            bar_btn = gr.Button(\"Bar plot\")\n",
        "            pie_btn = gr.Button(\"Pie chart\")\n",
        "            heat_btn = gr.Button(\"Food Availability Heatmap\")\n",
        "            trend_btn = gr.Button(\"Claims trend\")\n",
        "        bar_plot = gr.Plot()\n",
        "        pie_plot = gr.Plot()\n",
        "        heat_plot = gr.Plot()\n",
        "        trend_plot = gr.Plot()\n",
        "        bar_btn.click(plot_bar, inputs=[viz_table, viz_col], outputs=bar_plot)\n",
        "        pie_btn.click(plot_pie, inputs=[viz_table, viz_col], outputs=pie_plot)\n",
        "        heat_btn.click(plot_heatmap_foodavailability, inputs=None, outputs=heat_plot)\n",
        "        trend_btn.click(plot_claims_trend, inputs=None, outputs=trend_plot)\n",
        "\n",
        "    with gr.Tab(\"4️⃣ Search & Claim\"):\n",
        "        gr.Markdown(\"Search food listings with filters. Use `Claim this` to create a claim row.\")\n",
        "        with gr.Row():\n",
        "            q_text = gr.Textbox(label=\"Search text (Food_Name)\", value=\"\")\n",
        "            q_food_type = gr.Textbox(label=\"Food_Type filter (comma separated)\", value=\"\")\n",
        "            q_location = gr.Textbox(label=\"Location filter (comma separated)\", value=\"\")\n",
        "        with gr.Row():\n",
        "            q_meal_type = gr.Textbox(label=\"Meal_Type filter (comma separated)\", value=\"\")\n",
        "            q_provider_type = gr.Textbox(label=\"Provider_Type filter (comma separated)\", value=\"\")\n",
        "            q_qmin = gr.Number(label=\"Min Quantity\", value=0)\n",
        "            q_qmax = gr.Number(label=\"Max Quantity\", value=10**9)\n",
        "        search_btn = gr.Button(\"Search\")\n",
        "        search_out = gr.Textbox(label=\"Search Results (markdown)\")\n",
        "        search_btn.click(\n",
        "            lambda qt, ft, loc, mt, pt, qmin, qmax: search_food(\n",
        "                query_text=qt,\n",
        "                food_types=[s.strip() for s in ft.split(\",\")] if ft.strip() else None,\n",
        "                locations=[s.strip() for s in loc.split(\",\")] if loc.strip() else None,\n",
        "                meal_types=[s.strip() for s in mt.split(\",\")] if mt.strip() else None,\n",
        "                provider_types=[s.strip() for s in pt.split(\",\")] if pt.strip() else None,\n",
        "                qmin=int(qmin) if qmin is not None else None,\n",
        "                qmax=int(qmax) if qmax is not None else None,\n",
        "                limit=100\n",
        "            ),\n",
        "            inputs=[q_text, q_food_type, q_location, q_meal_type, q_provider_type, q_qmin, q_qmax],\n",
        "            outputs=search_out\n",
        "        )\n",
        "        with gr.Row():\n",
        "            claim_foodid = gr.Number(label=\"Food_ID to claim (from search results)\", value=0)\n",
        "            claim_receiverid = gr.Number(label=\"Receiver_ID\", value=0)\n",
        "            claim_btn = gr.Button(\"Claim this Food\")\n",
        "        claim_out = gr.Textbox()\n",
        "        claim_btn.click(claim_food, inputs=[claim_foodid, claim_receiverid, gr.Textbox(value=\"\")], outputs=claim_out)\n",
        "\n",
        "    with gr.Tab(\"5️⃣ SQL Query\"):\n",
        "        gr.Markdown(\"Run custom SQL queries against the in-memory SQLite DB. Useful tables: providers, receivers, food_listings, claims.\")\n",
        "        predefined = gr.Dropdown(label=\"Predefined queries\", choices=list(PREDEFINED_QUERIES.keys()), value=\"Show tables\")\n",
        "        sql_area = gr.Textbox(lines=6, label=\"SQL Query\", value=PREDEFINED_QUERIES[\"Show tables\"])\n",
        "        run_pre_btn = gr.Button(\"Load Predefined into SQL box\")\n",
        "        run_sql_btn = gr.Button(\"Run SQL\")\n",
        "        sql_out = gr.Textbox(label=\"Result / Preview\")\n",
        "        run_pre_btn.click(lambda key: PREDEFINED_QUERIES[key], inputs=[predefined], outputs=[sql_area])\n",
        "        run_sql_btn.click(run_sql, inputs=[sql_area], outputs=[sql_out])\n",
        "\n",
        "    with gr.Tab(\"6️⃣ AI/ML\"):\n",
        "        gr.Markdown(\"Train & evaluate ML models for Claim Success (classification) and Demand Forecasting (regression).\")\n",
        "        with gr.Row():\n",
        "            clf_model = gr.Dropdown(label=\"Classifier\", choices=[\"RandomForest\",\"LogisticRegression\",\"XGBoost\"], value=\"RandomForest\")\n",
        "            clf_btn = gr.Button(\"Train Claim Classifier\")\n",
        "        clf_out = gr.Textbox()\n",
        "        clf_btn.click(train_claim_classifier, inputs=[clf_model], outputs=[clf_out])\n",
        "\n",
        "        with gr.Row():\n",
        "            reg_model = gr.Dropdown(label=\"Regressor\", choices=[\"RandomForest\",\"LinearRegression\"], value=\"RandomForest\")\n",
        "            reg_btn = gr.Button(\"Train Demand Model\")\n",
        "        reg_out = gr.Textbox()\n",
        "        reg_btn.click(train_demand_model, inputs=[reg_model], outputs=[reg_out])\n",
        "\n",
        "        gr.Markdown(\"Predict demand for a specific Location & Food_Type after training demand model.\")\n",
        "        with gr.Row():\n",
        "            pred_loc = gr.Textbox(label=\"Location\", value=\"\")\n",
        "            pred_food = gr.Textbox(label=\"Food_Type\", value=\"\")\n",
        "            pred_btn = gr.Button(\"Predict Demand\")\n",
        "        pred_out = gr.Textbox()\n",
        "        pred_btn.click(predict_demand, inputs=[pred_loc, pred_food], outputs=[pred_out])\n",
        "\n",
        "    with gr.Tab(\"🔧 Debug / Tables\"):\n",
        "        gr.Markdown(\"Quick view of loaded tables.\")\n",
        "        table_name_view = gr.Textbox(label=\"Table name\", value=\"food_listings\")\n",
        "        view_btn = gr.Button(\"Show head\")\n",
        "        view_out = gr.Dataframe()\n",
        "        view_btn.click(lambda t: dataframes[t].head(50) if t in dataframes else pd.DataFrame(), inputs=[table_name_view], outputs=[view_out])\n",
        "\n",
        "    with gr.Row():\n",
        "        gr.Markdown(\"----\")\n",
        "        gr.Markdown(\"App created by your assistant. Use `share=True` to get a public URL when launched.\")\n",
        "\n",
        "# Launch app with public link\n",
        "demo.launch(share=True, server_name=\"0.0.0.0\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "egtM0mrGKhs8",
        "outputId": "66eaaa91-0e97-4c44-d902-2b99d43cdfa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://7d252f32d4e5ea5eeb.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7d252f32d4e5ea5eeb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SJbJx9EjSW_g"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwkXEbNd0uVRBgbSVUkpF2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}